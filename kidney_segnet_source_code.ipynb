{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "kidney_segnet_source_code_latest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL7yBZz2AimX"
      },
      "source": [
        "## Mounting google drive for file handling\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yUR0CrlAimd"
      },
      "source": [
        "## Copying dist utils for dice module utilities\n",
        "\n",
        "!cp -rv \"ENTER FILE PATH OF dist_utils HERE\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RCK1HN3DLQp"
      },
      "source": [
        "## Importing necessary libraries\n",
        "\n",
        "import torch as tor\n",
        "import torch.nn as nn\n",
        "import torchvision as tv\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision as tv\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from dist_utils.nn_layers.cnn_utils import *\n",
        "import math\n",
        "import time\n",
        "from PIL import Image as im\n",
        "\n",
        "from sklearn.metrics import f1_score \n",
        "import dist_utils.postprocessing as pp\n",
        "from sklearn.metrics import jaccard_score \n",
        "import random\n",
        "\n",
        "import statistics as stats\n",
        "import copy\n",
        "from dist_utils.flops_compute import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHKBYA_maVqV"
      },
      "source": [
        "def calc_total_mean(datafiles,num_chn = 3,verbose = False):\n",
        "\n",
        "    \"\"\"\n",
        "        Method to calculate the dataset mean for zero-centering\n",
        "\n",
        "        Args:\n",
        "            datafiles - list of data file names\n",
        "            num_chn - Number of channels of the data images\n",
        "            verbose - verbosity for debugging\n",
        "\n",
        "        Returns:\n",
        "            mean of dataset\n",
        "    \"\"\"\n",
        "\n",
        "    img_sum = 0\n",
        "    num_files = len(datafiles)\n",
        "\n",
        "    for e,file in enumerate(datafiles):\n",
        "\n",
        "        if(num_chn == 3):\n",
        "            img = cv2.resize(cv2.imread(file),(512,512))\n",
        "            img_sum += img\n",
        "        elif(num_chn == 1):\n",
        "            img = cv2.imread(file,0)\n",
        "            img_sum += img\n",
        "        else:\n",
        "            assert \"Incorrect number of channels\"\n",
        "\n",
        "        if(verbose):\n",
        "            print(e,file)\n",
        "\n",
        "\n",
        "    return np.float32(img_sum) / num_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPeLz3De-nOZ"
      },
      "source": [
        "\"\"\"\n",
        "NOTE: This code has been forked from https://github.com/sacmehta/EdgeNets. We thank sacmehta and team for this class definition. \n",
        "\"\"\"\n",
        "\n",
        "class dice(nn.Module):\n",
        "    '''\n",
        "    This class implements the volume-wise seperable convolutions\n",
        "    '''\n",
        "    def __init__(self, channel_in, channel_out, height, width, kernel_size=3, dilation=[1, 1, 1], shuffle=True):\n",
        "        '''\n",
        "        :param channel_in: # of input channels\n",
        "        :param channel_out: # of output channels\n",
        "        :param height: Height of the input volume\n",
        "        :param width: Width of the input volume\n",
        "        :param kernel_size: Kernel size. We use the same kernel size of 3 for each dimension. Larger kernel size would increase the FLOPs and Parameters\n",
        "        :param dilation: It's a list with 3 elements, each element corresponding to a dilation rate for each dimension.\n",
        "        :param shuffle: Shuffle the feature maps in the volume-wise separable convolutions\n",
        "        '''\n",
        "        super().__init__()\n",
        "        assert len(dilation) == 3\n",
        "        padding_1 = int((kernel_size - 1) / 2) *dilation[0] \n",
        "        padding_2 = int((kernel_size - 1) / 2) *dilation[1] \n",
        "        padding_3 = int((kernel_size - 1) / 2) *dilation[2] \n",
        "        self.conv_channel = nn.Conv2d(channel_in, channel_in, kernel_size=kernel_size, stride=1, groups=channel_in,\n",
        "                                      padding=padding_1, bias=False, dilation=dilation[0])\n",
        "        self.conv_width = nn.Conv2d(width, width, kernel_size=kernel_size, stride=1, groups=width,\n",
        "                               padding=padding_2, bias=False, dilation=dilation[1])\n",
        "        self.conv_height = nn.Conv2d(height, height, kernel_size=kernel_size, stride=1, groups=height,\n",
        "                               padding=padding_3, bias=False, dilation=dilation[2])\n",
        "\n",
        "        self.br_act = BR(3*channel_in)\n",
        "        self.weight_avg_layer = CBR(3*channel_in, channel_in, kSize=1, stride=1, groups=channel_in)\n",
        "\n",
        "        # project from channel_in to Channel_out\n",
        "        groups_proj = math.gcd(channel_in, channel_out)\n",
        "        self.proj_layer = CBR(channel_in, channel_out, kSize=3, stride=1, groups=groups_proj)\n",
        "        self.linear_comb_layer = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(output_size=1),\n",
        "            nn.Conv2d(channel_in, channel_in // 4, kernel_size=1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channel_in //4, channel_out, kernel_size=1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.vol_shuffle = Shuffle(3)\n",
        "\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.channel_in = channel_in\n",
        "        self.channel_out = channel_out\n",
        "        self.shuffle = shuffle\n",
        "        self.ksize=kernel_size\n",
        "        self.dilation = dilation\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x: input of dimension C x H x W\n",
        "        :return: output of dimension C1 x H x W\n",
        "        '''\n",
        "        bsz, channels, height, width = x.size()\n",
        "        # process across channel. Input: C x H x W, Output: C x H x W\n",
        "        out_ch_wise = self.conv_channel(x)\n",
        "\n",
        "        # process across height. Input: H x C x W, Output: C x H x W\n",
        "        x_h_wise = x.clone()\n",
        "        if height != self.height:\n",
        "            if height < self.height:\n",
        "                x_h_wise = F.interpolate(x_h_wise, mode='bilinear', size=(self.height, width), align_corners=True)\n",
        "            else:\n",
        "                x_h_wise = F.adaptive_avg_pool2d(x_h_wise, output_size=(self.height, width))\n",
        "\n",
        "        x_h_wise = x_h_wise.transpose(1, 2).contiguous()\n",
        "        out_h_wise = self.conv_height(x_h_wise).transpose(1, 2).contiguous()\n",
        "\n",
        "        h_wise_height = out_h_wise.size(2)\n",
        "        if height != h_wise_height:\n",
        "            if h_wise_height < height:\n",
        "                out_h_wise = F.interpolate(out_h_wise, mode='bilinear', size=(height, width), align_corners=True)\n",
        "            else:\n",
        "                out_h_wise = F.adaptive_avg_pool2d(out_h_wise, output_size=(height, width))\n",
        "\n",
        "        # process across width: Input: W x H x C, Output: C x H x W\n",
        "        x_w_wise = x.clone()\n",
        "        if width != self.width:\n",
        "            if width < self.width:\n",
        "                x_w_wise = F.interpolate(x_w_wise, mode='bilinear', size=(height, self.width), align_corners=True)\n",
        "            else:\n",
        "                x_w_wise = F.adaptive_avg_pool2d(x_w_wise, output_size=(height, self.width))\n",
        "\n",
        "        x_w_wise = x_w_wise.transpose(1, 3).contiguous()\n",
        "        out_w_wise = self.conv_width(x_w_wise).transpose(1, 3).contiguous()\n",
        "        w_wise_width = out_w_wise.size(3)\n",
        "        if width != w_wise_width:\n",
        "            if w_wise_width < width:\n",
        "                out_w_wise = F.interpolate(out_w_wise, mode='bilinear', size=(height, width), align_corners=True)\n",
        "            else:\n",
        "                out_w_wise = F.adaptive_avg_pool2d(out_w_wise, output_size=(height, width))\n",
        "\n",
        "        # Merge. Output will be 3C x H X W\n",
        "        outputs = torch.cat((out_ch_wise, out_h_wise, out_w_wise), 1)\n",
        "        outputs = self.br_act(outputs)\n",
        "\n",
        "        if self.shuffle:\n",
        "            outputs = self.vol_shuffle(outputs)\n",
        "        outputs = self.weight_avg_layer(outputs)\n",
        "        linear_wts = self.linear_comb_layer(outputs)\n",
        "        proj_out = self.proj_layer(outputs)\n",
        "        return proj_out * linear_wts\n",
        "\n",
        "    def __repr__(self):\n",
        "        s = '{name}(in_channels={channel_in}, out_channels={channel_out}, kernel_size={ksize}, vol_shuffle={shuffle}, ' \\\n",
        "            'width={width}, height={height}, dilation={dilation})'\n",
        "        return s.format(name=self.__class__.__name__, **self.__dict__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwnR2yWbljmH"
      },
      "source": [
        "class aspp(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "        Class definition of the ASPP (atrous spatial pyramid pooling) module \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,in_channels,mid_channels,prev_dim,rates):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        r1,r2,r3 = rates\n",
        "\n",
        "        self.branch1 = dice(in_channels,mid_channels,prev_dim[0],prev_dim[1],kernel_size = 1)\n",
        "        self.branch2 = dice(in_channels,mid_channels,prev_dim[0],prev_dim[1],kernel_size = 3,dilation = [r1,r1,r1])\n",
        "        self.branch3 = dice(in_channels,mid_channels,prev_dim[0],prev_dim[1],kernel_size = 3,dilation = [r2,r2,r2])\n",
        "        self.branch4 = dice(in_channels,mid_channels,prev_dim[0],prev_dim[1],kernel_size = 3,dilation = [r3,r3,r3])\n",
        "\n",
        "        self.branch5 = nn.AvgPool2d(kernel_size = prev_dim)\n",
        "\n",
        "        self.prev_dim = prev_dim\n",
        "\n",
        "        self.upsample = nn.UpsamplingBilinear2d(size = prev_dim)\n",
        "\n",
        "        self.final_layer = nn.Conv2d(in_channels = mid_channels * 4 + in_channels,out_channels = in_channels,kernel_size = (1,1))\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        out1 = self.upsample(self.branch1(x))\n",
        "        out2 = self.upsample(self.branch2(x))\n",
        "        out3 = self.upsample(self.branch3(x))\n",
        "        out4 = self.upsample(self.branch4(x))\n",
        "        out5 = self.upsample(self.branch5(x))\n",
        "\n",
        "        out = tor.cat((out1,out2,out3,out4,out5),dim = 1)\n",
        "\n",
        "        out = self.final_layer(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hmAKQUCv1Yb"
      },
      "source": [
        "class att_block(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "        Class definition of the attention block\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,in_chnx,in_chng,mid_chn):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.lx = nn.Conv2d(in_chnx,mid_chn,kernel_size = (1,1),padding = 0)\n",
        "\n",
        "        self.lg = nn.Conv2d(in_chng,mid_chn,kernel_size = (1,1),padding = 0)\n",
        "        self.upconv = nn.ConvTranspose2d(in_channels = mid_chn,out_channels = mid_chn, kernel_size = (3,3), stride = 2, padding = 1, output_padding = 1)\n",
        "\n",
        "        self.lmid = nn.Conv2d(mid_chn,1,kernel_size = (1,1),padding = 0)\n",
        "\n",
        "        self.resamp = nn.Conv2d(1,in_chnx,kernel_size = (1,1),padding = 0)\n",
        "\n",
        "    def forward(self,x,g):\n",
        "\n",
        "        x1 = self.lx(x)\n",
        "        \n",
        "        g = self.lg(g)\n",
        "        g = self.upconv(g)\n",
        "\n",
        "        res = x1 + g\n",
        "\n",
        "        res = nn.ReLU()(res)\n",
        "\n",
        "        res = self.lmid(res)\n",
        "\n",
        "        res = nn.Sigmoid()(res)\n",
        "\n",
        "        res = self.resamp(res)\n",
        "\n",
        "        res = res * x\n",
        "\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aszx-Sh9E2Vb"
      },
      "source": [
        "class dist_dice(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "        Kidney-SegNet model definition\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,in_channels,nfeat,mid_channels = 256):\n",
        "\n",
        "        self.drop = nn.Dropout\n",
        "\n",
        "        super().__init__()\n",
        "        self.conv1a = nn.Conv2d(in_channels = in_channels,out_channels = nfeat,kernel_size = (3,3),padding = 1)\n",
        "        self.bn1a = nn.BatchNorm2d(nfeat)\n",
        "        self.conv1b = dice(nfeat,nfeat,height = 512,width = 512)\n",
        "        self.bn1b = nn.BatchNorm2d(nfeat)\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size = (2,2), stride = 2)\n",
        "\n",
        "        self.conv2a = dice(nfeat,2 * nfeat,width = 256,height = 256)\n",
        "        self.bn2a = nn.BatchNorm2d(2 * nfeat)\n",
        "        self.conv2b = dice(2 * nfeat,2 * nfeat,width = 256,height = 256)\n",
        "        self.bn2b = nn.BatchNorm2d(2 * nfeat)\n",
        "\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size = (2,2), stride = 2)\n",
        "\n",
        "        self.conv3a = dice(2 * nfeat,4 * nfeat,width = 128,height = 128)\n",
        "        self.bn3a = nn.BatchNorm2d(4 * nfeat)\n",
        "        self.conv3b = dice(4 * nfeat,4 * nfeat,width = 128,height = 128)\n",
        "        self.bn3b = nn.BatchNorm2d(4 * nfeat)\n",
        "\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size = (2,2),stride = 2)\n",
        "\n",
        "        self.conv4a = dice(4 * nfeat,8 * nfeat,width = 64,height = 64)\n",
        "        self.bn4a = nn.BatchNorm2d(8 * nfeat)\n",
        "        self.conv4b = dice(8 * nfeat,8 * nfeat,width = 64,height = 64)\n",
        "        self.bn4b = nn.BatchNorm2d(8 * nfeat)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(in_channels = 8 * nfeat,out_channels = 4 * nfeat, kernel_size = (3,3), stride = 2, padding = 1, output_padding = 1)\n",
        "\n",
        "        self.conv6a = dice(8 * nfeat,4 * nfeat,width = 128,height = 128)\n",
        "        self.bn6a = nn.BatchNorm2d(4 * nfeat)\n",
        "        self.conv6b = dice(4 * nfeat,4 * nfeat,width = 128,height = 128)\n",
        "        self.bn6b = nn.BatchNorm2d(4 * nfeat)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(in_channels = 4 * nfeat,out_channels = 2 * nfeat, kernel_size = (3,3), stride = 2, padding = 1, output_padding = 1)\n",
        "\n",
        "        self.conv7a = dice(4 * nfeat,2 * nfeat,width = 256,height = 256)\n",
        "        self.bn7a = nn.BatchNorm2d(2 * nfeat)\n",
        "        self.conv7b = dice(2 * nfeat,2 * nfeat,width = 256,height = 256)\n",
        "        self.bn7b = nn.BatchNorm2d(2 * nfeat)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(in_channels = 2 * nfeat,out_channels = nfeat, kernel_size = (3,3), stride = 2, padding = 1, output_padding = 1)\n",
        "\n",
        "        self.conv8a = dice(2 * nfeat,nfeat,width = 512,height = 512)\n",
        "        self.bn8a = nn.BatchNorm2d(nfeat)\n",
        "        self.conv8b = dice(nfeat,nfeat,width = 512,height = 512)\n",
        "        self.bn8b = nn.BatchNorm2d(nfeat)\n",
        "\n",
        "        self.seg_map_conv = nn.Conv2d(in_channels = nfeat,out_channels = 1, kernel_size = (1,1))\n",
        "\n",
        "        self.load_p(0)\n",
        "\n",
        "        self.aspp = aspp(in_channels = 8 * nfeat,mid_channels = mid_channels,prev_dim = (64,64),rates = [4,6,8])\n",
        "\n",
        "        self.att1 = att_block(in_chnx = 4 * nfeat,in_chng = 8 * nfeat,mid_chn = 4 * nfeat)\n",
        "        self.att2 = att_block(in_chnx = 2 * nfeat,in_chng = 4 * nfeat,mid_chn = 2 * nfeat)\n",
        "        self.att3 = att_block(in_chnx = nfeat,in_chng = 2 * nfeat,mid_chn = nfeat)\n",
        "        \n",
        "\n",
        "        # self.aspp1 = aspp(in_channels = 2 * nfeat, mid_channels = 64,prev_dim = (128,128),rates = [4,6,8])\n",
        "        # self.aspp2 = aspp(in_channels = nfeat, mid_channels = 32,prev_dim = (256,256),rates = [4,6,8])\n",
        "\n",
        "    def load_p(self,p):\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self,inp):\n",
        "\n",
        "        out1 = nn.ReLU()(self.bn1a(self.conv1a(inp)))\n",
        "        out1 = nn.ReLU()(self.bn1b(self.conv1b(out1)))\n",
        "        out2 = self.maxpool1(out1)\n",
        "\n",
        "        out2 = nn.ReLU()(self.bn2a(self.conv2a(out2)))\n",
        "        out2 = nn.ReLU()(self.bn2b(self.conv2b(out2)))\n",
        "        out3 = self.maxpool2(out2)\n",
        "\n",
        "        out3 = nn.ReLU()(self.bn3a(self.conv3a(out3)))\n",
        "        out3 = nn.ReLU()(self.bn3b(self.conv3b(out3)))\n",
        "        out4 = self.maxpool3(out3)\n",
        "\n",
        "        out4 = nn.ReLU()(self.bn4a(self.conv4a(out4)))\n",
        "        out4 = nn.ReLU()(self.bn4b(self.conv4b(out4)))\n",
        "        \n",
        "        out_aspp = self.aspp(out4)\n",
        "\n",
        "        # out6 = self.upconv1(out_aspp)\n",
        "        out6 = self.att1(out3,out_aspp)\n",
        "\n",
        "        out6 = tor.cat((out6,out3),dim = 1)\n",
        "        del out4\n",
        "\n",
        "        out6 = nn.ReLU()(self.bn6a(self.conv6a(out6)))\n",
        "        out6 = nn.ReLU()(self.bn6b(self.conv6b(out6)))\n",
        "        # out7 = self.upconv2(out6)\n",
        "        out7 = self.att2(out2,out6)\n",
        "\n",
        "        out7 = tor.cat((out7,out2),dim = 1)\n",
        "        del out3\n",
        "        del out6\n",
        "\n",
        "        out7 = nn.ReLU()(self.bn7a(self.conv7a(out7)))\n",
        "        out7 = nn.ReLU()(self.bn7b(self.conv7b(out7)))\n",
        "        # out8 = self.upconv3(out7)\n",
        "        out8 = self.att3(out1,out7)\n",
        "\n",
        "        # out1 = self.aspp2(out1)\n",
        "        out8 = tor.cat((out8,out1),dim = 1)\n",
        "        del out2\n",
        "        del out7\n",
        "\n",
        "        out8 = nn.ReLU()(self.bn8a(self.conv8a(out8)))\n",
        "        out8 = nn.ReLU()(self.bn8b(self.conv8b(out8)))\n",
        "        \n",
        "        out = nn.ReLU()(self.seg_map_conv(out8))\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qClIsAZLZ34"
      },
      "source": [
        "def get_f1(gt,pred):\n",
        "\n",
        "    f1 = []\n",
        "    m = gt.shape[0]\n",
        "\n",
        "    if(not isinstance(gt,np.ndarray)):\n",
        "        # gt = gt.detach().cpu().numpy().squeeze()\n",
        "        gt = gt.detach().cpu().numpy()\n",
        "\n",
        "    if(not isinstance(pred,np.ndarray)):\n",
        "        # pred = pred.detach().cpu().numpy().squeeze()\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "\n",
        "    # print(\"pred.shape: \",pred.shape)\n",
        "    # print(\"gt.shape: \",gt.shape)\n",
        "\n",
        "    for predicted,ground_truth in zip(pred,gt):\n",
        "        predicted = ((predicted - predicted.min()) / (predicted.max() - predicted.min())) * 1\n",
        "        predicted = np.uint8(predicted)\n",
        "\n",
        "        ground_truth = ((ground_truth - ground_truth.min()) / (ground_truth.max() - ground_truth.min())) * 1\n",
        "        ground_truth = np.uint8(ground_truth)\n",
        "\n",
        "        predicted = predicted.flatten()\n",
        "        ground_truth = ground_truth.flatten()\n",
        "\n",
        "        predicted = np.uint8(predicted)\n",
        "        ground_truth = np.uint8(ground_truth)\n",
        "\n",
        "        # print(\"predicted.shape: \",predicted.shape)\n",
        "        # print(\"ground_truth.shape: \",ground_truth.shape)\n",
        "\n",
        "        f1.append(f1_score(ground_truth,predicted))\n",
        "\n",
        "    return np.mean(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4akDG3NLZ4W"
      },
      "source": [
        "def get_ji(gt,pred):\n",
        "\n",
        "    ji = []\n",
        "    m = gt.shape[0]\n",
        "\n",
        "    if(not isinstance(gt,np.ndarray)):\n",
        "        # gt = gt.detach().cpu().numpy().squeeze()\n",
        "        gt = gt.detach().cpu().numpy()\n",
        "\n",
        "    if(not isinstance(pred,np.ndarray)):\n",
        "        # pred = pred.detach().cpu().numpy().squeeze()\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "\n",
        "    for predicted,ground_truth in zip(pred,gt):\n",
        "        predicted = ((predicted - predicted.min()) / (predicted.max() - predicted.min())) * 1\n",
        "        predicted = np.uint8(predicted)\n",
        "\n",
        "        ground_truth = ((ground_truth - ground_truth.min()) / (ground_truth.max() - ground_truth.min())) * 1\n",
        "        ground_truth = np.uint8(ground_truth)\n",
        "\n",
        "        predicted = predicted.flatten()\n",
        "        ground_truth = ground_truth.flatten()\n",
        "\n",
        "        predicted = np.uint8(predicted)\n",
        "        ground_truth = np.uint8(ground_truth)\n",
        "\n",
        "        ji.append(jaccard_score(ground_truth,predicted))\n",
        "\n",
        "    return np.mean(ji)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Bptz7oAc9h"
      },
      "source": [
        "Dataset file structure:\n",
        "\n",
        "    [TRAIN/VAL/TEST DIR]\n",
        "            |\n",
        "            |\n",
        "            |___________________\n",
        "            |         |        |\n",
        "            data     labels    gts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvPuRxB5D99s"
      },
      "source": [
        "class dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    \"\"\"\n",
        "        Dataset definition class\n",
        "    \"\"\"\n",
        "\n",
        "    total_mean = 0\n",
        "\n",
        "    def __init__(self,files_dir,data_size = -1,phase = \"\",apply_transforms = True):\n",
        "\n",
        "        data_dir = os.path.join(files_dir,\"data\")\n",
        "        label_dir = os.path.join(files_dir,\"labels\")\n",
        "        gt_dir = os.path.join(files_dir,\"gts\")\n",
        "\n",
        "        files = os.listdir(gt_dir)\n",
        "        # label_files = os.listdir(label_dir)\n",
        "        # gt_files = os.listdir(gt_dir)\n",
        "\n",
        "        data_files = [os.path.join(data_dir,x) for x in files]\n",
        "        label_files = [os.path.join(label_dir,x) for x in files]\n",
        "        gt_files = [os.path.join(gt_dir,x) for x in files]\n",
        "\n",
        "        if(data_size == -1):\n",
        "            data_size = len(data_files)\n",
        "\n",
        "        self.data_files = data_files\n",
        "        self.label_files = label_files\n",
        "        self.gt_files = gt_files\n",
        "        self.data_size = data_size\n",
        "        self.apply_transforms = apply_transforms\n",
        "\n",
        "        if(phase == \"train\"):\n",
        "          dataset.total_mean = tor.from_numpy(calc_total_mean(self.data_files))\n",
        "          dataset.total_mean = dataset.total_mean.permute(2,0,1)\n",
        "          \n",
        "        print(\"shape of dataset.total_mean: \",dataset.total_mean.size())\n",
        "\n",
        "        del data_files\n",
        "        del label_files\n",
        "        del gt_files\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def transforms(self,data,label,gt):\n",
        "\n",
        "        data = data.resize((512,512))\n",
        "        label = label.resize((512,512))\n",
        "        gt = gt.resize((512,512))\n",
        "\n",
        "        # Random horizontal flip\n",
        "        if(random.random() > 0.5):\n",
        "            data = TF.hflip(data)\n",
        "            label = TF.hflip(label)\n",
        "            gt = TF.hflip(gt)\n",
        "\n",
        "        ## Random Vertical Flip\n",
        "        if(random.random() > 0.5):\n",
        "            data = TF.vflip(data)\n",
        "            label = TF.vflip(label)\n",
        "            gt = TF.vflip(gt)\n",
        "\n",
        "        ## Random rotate in multiples of 90\n",
        "        range_of_angles = [0,90,180,270]\n",
        "        angle = random.choice(range_of_angles)\n",
        "        data = TF.rotate(data,angle)\n",
        "        label = TF.rotate(label,angle,fill = (0,))\n",
        "        gt = TF.rotate(gt,angle,fill = (0,))\n",
        "        \n",
        "        ## Applying color-jitter to data\n",
        "        # data = transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)(data)\n",
        "\n",
        "        return data,label,gt\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        data = self.data_files[idx]\n",
        "        label = self.label_files[idx]\n",
        "        gt = self.gt_files[idx]\n",
        "\n",
        "        # print(label)\n",
        "\n",
        "        data = im.open(data)\n",
        "        label = im.open(label)\n",
        "        gt = im.open(gt)\n",
        "        gt = gt.convert('L')\n",
        "\n",
        "        if(self.apply_transforms):\n",
        "          data,label,gt = self.transforms(data,label,gt)\n",
        "        else:\n",
        "          data = data.resize((512,512))\n",
        "          label = label.resize((512,512))\n",
        "          gt = gt.resize((512,512))\n",
        "\n",
        "        ## Convert PILs to tensors\n",
        "        data = transforms.ToTensor()(data)[:3,:,:]\n",
        "        label = transforms.ToTensor()(label)\n",
        "        gt = transforms.ToTensor()(gt)\n",
        "\n",
        "        label = label.type(tor.FloatTensor)\n",
        "        gt = gt.type(tor.LongTensor)\n",
        "        \n",
        "        data = ((data - data.min()) / (data.max() - data.min())) * 255\n",
        "        label = ((label - label.min()) / (label.max() - label.min())) * 255\n",
        "\n",
        "        if(tor.sum(tor.isnan(label))):\n",
        "            print(self.label_files[idx],\"nan\")\n",
        "        if(tor.sum(tor.isnan(data))):\n",
        "            print(self.label_files[idx],\"nan\")\n",
        "        if(tor.sum(tor.isnan(gt))):\n",
        "            print(self.label_files[idx],\"nan\")\n",
        "\n",
        "        ## subtracting the mean\n",
        "        data = data - dataset.total_mean\n",
        "\n",
        "        return data,label,gt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkhHV6FeDc3e"
      },
      "source": [
        "## Extract training dataset\n",
        "\n",
        "# Train directory containing the data, label and gt directories\n",
        "train_dir = \"ENTER TRAIN DIR NAME\"\n",
        "\n",
        "trainset = dataset(files_dir = train_dir,phase = \"train\",apply_transforms=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 2,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX2wd6RQDc3m"
      },
      "source": [
        "## Extract validation dataset\n",
        "\n",
        "# Validation data directory containing the data, label and gt directories\n",
        "val_dir = \"ENTER VAL DIR NAME\"\n",
        "\n",
        "valset = dataset(files_dir=val_dir,apply_transforms=False)\n",
        "valloader = torch.utils.data.DataLoader(valset,batch_size=2,shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRiSXfkiSsUE"
      },
      "source": [
        "def get_segments(distmaps,param = 7,thresh1 = 0.5,thresh2 = 5):\n",
        "\n",
        "    \"\"\"\n",
        "        Method to extract segmentations from distance map regressions\n",
        "\n",
        "        Args:\n",
        "            distmaps - distance map regressions\n",
        "            param, thresh1, thresh2 - hyper-parameters for segmentation\n",
        "        \n",
        "        Returns:\n",
        "            segmentation outputs from distance maps\n",
        "    \"\"\"\n",
        "\n",
        "    segments = []\n",
        "\n",
        "    for res in distmaps:\n",
        "\n",
        "        if(not isinstance(res,np.ndarray)):\n",
        "            res = res.detach().cpu().numpy().squeeze()\n",
        "            \n",
        "        res = ((res - res.min()) / (res.max() - res.min())) * 255\n",
        "        res = np.uint8(res)\n",
        "        res[res<thresh2] = 0 \n",
        "\n",
        "        res = pp.PostProcess(res,param = param,thresh = thresh1)\n",
        "        res[res!=0] = 1\n",
        "\n",
        "        segments.append(res)\n",
        "\n",
        "    segments = np.array(segments)\n",
        "\n",
        "    return segments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEijxmetwqQO"
      },
      "source": [
        "def train(seg,epochs,dataloaders,hyper_params,reset = True,save = False):\n",
        "\n",
        "  \"\"\"\n",
        "        Method to perform training\n",
        "\n",
        "        Args:\n",
        "            seg - segmentation object\n",
        "            epochs - number of epochs to be trained\n",
        "            dataloaders - list of dataloaders\n",
        "            hyper_params - list of various hyper-parameters\n",
        "            reset - toggle to reset weights of model\n",
        "            save - toggle to save model\n",
        "\n",
        "        Returns:\n",
        "            Training history  \n",
        "  \"\"\"\n",
        "\n",
        "  global past\n",
        "\n",
        "  trainloader,valloader,bridgeloader = dataloaders\n",
        "\n",
        "  lr,reg,p,nfeat,postproc_params = hyper_params\n",
        "\n",
        "  if(postproc_params):\n",
        "      param,thresh1,thresh2 = postproc_params\n",
        "  else:\n",
        "      param = 7\n",
        "      thresh1 = 0.5\n",
        "      thresh2 = 20\n",
        "\n",
        "  seg.load_p(p)\n",
        "\n",
        "  if(reset):\n",
        "    del seg\n",
        "    seg = dist_dice(in_channels=3,nfeat = nfeat).to(device)\n",
        "    print(\"/////////////////// Weights have been reset \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
        "\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(seg.parameters(),lr = lr,weight_decay = reg)\n",
        "\n",
        "  epoch_losses = []\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "      batch_losses = []\n",
        "      batch_f1 = []\n",
        "      batch_ji = []\n",
        "\n",
        "      for batch_idx,(data,label,gt) in enumerate(trainloader):\n",
        "\n",
        "          data,label = data.to(device),label.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          out = seg(data) \n",
        "          loss = criterion(out,label)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          segment_maps = get_segments(out,param = param,thresh1 = thresh1,thresh2 = thresh2)\n",
        "\n",
        "          batch_f1.append(get_f1(gt,segment_maps))\n",
        "          batch_ji.append(get_ji(gt,segment_maps))\n",
        "\n",
        "          batch_losses.append(loss.item())\n",
        "\n",
        "          if(math.isnan(loss.item())):\n",
        "              print(\"batch_loss nan\")\n",
        "              print(\"data: \",tor.sum(tor.isnan(data)))\n",
        "              print(\"out: \",tor.sum(tor.isnan(out)))\n",
        "              print(\"label: \",tor.sum(tor.isnan(label)))\n",
        "              print(\"gt: \",tor.sum(tor.isnan(gt)))\n",
        "            #   input(\"\")\n",
        "\n",
        "      epoch_losses.append(np.mean(batch_losses))\n",
        "\n",
        "      # print(\"Epoch: \",epoch,\"\\tEpoch Loss: \",epoch_losses[-1],\"\\tTrain acc: \",(correct*100.0/total)) \n",
        "      print(\"Epoch: \",epoch,\"\\tEpoch Loss: \",epoch_losses[-1],\"Mean f1: \",np.mean(batch_f1))\n",
        "      print(\"Mean ji: \",np.mean(batch_ji),\"HM: \",stats.harmonic_mean([np.mean(batch_f1),np.mean(batch_ji)]))\n",
        "      \n",
        "      if(math.isnan(epoch_losses[-1])):\n",
        "          print(\"batch_losses: \",batch_losses)\n",
        "          break\n",
        "      \n",
        "      seg.eval()\n",
        "      with tor.no_grad():\n",
        "\n",
        "\n",
        "          batch_losses = []\n",
        "          batch_f1 = []\n",
        "          batch_ji = []\n",
        "\n",
        "          for batch_idx,(valdata,vallabel,valgt) in enumerate(valloader):\n",
        "\n",
        "              valdata,vallabel = valdata.to(device),vallabel.to(device)\n",
        "\n",
        "              valout = seg(valdata)\n",
        "              loss = criterion(valout,vallabel)\n",
        "\n",
        "              segment_maps = get_segments(valout,param = param,thresh1 = thresh1,thresh2 = thresh2)\n",
        "              batch_losses.append(loss.item())\n",
        "              batch_f1.append(get_f1(valgt,segment_maps))\n",
        "              batch_ji.append(get_ji(valgt,segment_maps))\n",
        "\n",
        "          print(\"Val Loss: \",np.mean(batch_losses),\"Mean f1: \",np.mean(batch_f1))\n",
        "          print(\"Mean ji: \",np.mean(batch_ji),\"HM: \",stats.harmonic_mean([np.mean(batch_f1),np.mean(batch_ji)]))\n",
        "      \n",
        "\n",
        "      if(stats.harmonic_mean([np.mean(batch_f1),np.mean(batch_ji)]) > past):\n",
        "        state = [seg.state_dict(),hyper_params,[np.mean(batch_f1),np.mean(batch_ji),stats.harmonic_mean([np.mean(batch_f1),np.mean(batch_ji)])]]\n",
        "        tor.save(state,\"ENTER FILE PATH WHERE WEIGHTS SHOULD BE SAVED\")\n",
        "        print(\"************************best model saved*********************************\")\n",
        "        past = stats.harmonic_mean([np.mean(batch_f1),np.mean(batch_ji)])\n",
        "\n",
        "      # save_model(seg)\n",
        "      print(\"-------------------------------------------------------------------------\")\n",
        "      seg.train()\n",
        "\n",
        "  return epoch_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chf-8bqHbfzC"
      },
      "source": [
        "## Function to count the number of parameters in a pytorch model\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad),sum(p.numel() for p in model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I728V5OBbfzG"
      },
      "source": [
        "## setting up training\n",
        "\n",
        "device = tor.device(\"cuda:0\" if tor.cuda.is_available() else \"cpu\")\n",
        "print(\"using: \",device)\n",
        "\n",
        "nfeat = 32\n",
        "seg = dist_dice(in_channels=3,nfeat = nfeat).to(device)\n",
        "seg = add_flops_counting_methods(seg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPC0LxjD1eA"
      },
      "source": [
        "## Calculate the number of parameters\n",
        "\n",
        "train_params,total_params = count_parameters(seg)\n",
        "print(\"Number of trainable params: \",train_params)\n",
        "print(\"total params: \",total_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdaxCQ28aCku"
      },
      "source": [
        "## The next 3 cells are used to load an already existing previous model. \n",
        "___________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJRu8GdgD1eD"
      },
      "source": [
        "## Load previous past best model score\n",
        "\n",
        "# file path to model weights\n",
        "state = tor.load(\"ENTER FILE PATH TO MODEL WEIGHTS HERE\")\n",
        "state3 = state[2]\n",
        "past = state3[2]\n",
        "print(\"past best = \",past,state3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SiJNFFfD1eF"
      },
      "source": [
        "## make segmentation model weights the same as previous best model weights\n",
        "\n",
        "seg.load_state_dict(state[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pRKTo5SD1eG"
      },
      "source": [
        "## training mode\n",
        "\n",
        "_ = seg.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEDd9plOaCkw"
      },
      "source": [
        "________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVADmNOVaCkw"
      },
      "source": [
        "# The training process\n",
        "\n",
        "### The following cell performs the training for the Kidney-Segnet framework. In order to train the network effectively, it is important to tune the hyper-parameters.\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll-47ZbXbvUU"
      },
      "source": [
        "epochs = 1000\n",
        "nfeat = 32\n",
        "lr = 7 * 1e-4\n",
        "reg = 0.7 * 1e-3\n",
        "reset = True\n",
        "p = 0.0\n",
        "past = 0.0\n",
        "dataloaders = [trainloader,testloader,0.0]\n",
        "postproc_params = [7,0.5,24]\n",
        "# postproc_params = [65,0.5,18]\n",
        "hyper_params = [lr,reg,p,nfeat,postproc_params]\n",
        "\n",
        "_ = train(seg,epochs,dataloaders,hyper_params = hyper_params,reset = reset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSrJmY0NaCkx"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orHDoVDlaCkx"
      },
      "source": [
        "# Testing the network\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEuRGi2kEA7D"
      },
      "source": [
        "## Extract test dataset\n",
        "\n",
        "# test data directory containing the data, label and gt directories\n",
        "test_dir = \"ENTER TEST DIR HERE\"\n",
        "\n",
        "testset = dataset(files_dir=test_dir,apply_transforms=False)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size=4,shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8AI7pYQEA7J"
      },
      "source": [
        "batch_losses = []\n",
        "batch_f1 = []\n",
        "batch_ji = []\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "param = 7\n",
        "thresh1 = 0.5\n",
        "thresh2 = 28\n",
        "\n",
        "imgs = []\n",
        "gts = []\n",
        "\n",
        "seg.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_idx,(testdata,testlabel,testgt) in enumerate(testloader):\n",
        "\n",
        "      testdata,testlabel = testdata.to(device),testlabel.to(device)\n",
        "\n",
        "      testout = seg(testdata)\n",
        "      loss = criterion(testout,testlabel)\n",
        "\n",
        "      segment_maps = get_segments(testout,param = param,thresh1 = thresh1,thresh2 = thresh2)\n",
        "      batch_losses.append(loss.item())\n",
        "      batch_f1.append(get_f1(testgt,segment_maps))\n",
        "      batch_ji.append(get_ji(testgt,segment_maps))\n",
        "\n",
        "      imgs.append(segment_maps)\n",
        "      gts.append(testgt)\n",
        "\n",
        "  print(\"Test Loss: \",np.mean(batch_losses),\"Mean f1: \",np.mean(batch_f1))\n",
        "  print(\"Mean ji: \",np.mean(batch_ji),\"HM: \",stats.harmonic_mean([np.mean(batch_f1),np.mean(batch_ji)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNaIbv88aCky"
      },
      "source": [
        "___"
      ]
    }
  ]
}